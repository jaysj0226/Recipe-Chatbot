import os, re, json, unicodedata
from pathlib import Path
from typing import Optional, List, Dict, Any

from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate

from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse

BASE_DIR   = Path(__file__).resolve().parent
STATIC_DIR = Path("C:/Users/SunjaeJeong/Desktop/data/files_data/recipe_chatbot_CRAG/static")      # test/static/
STATIC_DIR = BASE_DIR/"static"

load_dotenv(BASE_DIR / ".env")
load_dotenv(BASE_DIR / "rag_hybrid_app" / ".env")


# â”€â”€ App / Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
app = FastAPI(title="Group A â€” RAG with LLM Router (Enhanced)")

# ğŸ”§ ë²¡í„° DB ì„¤ì •
EMB = OpenAIEmbeddings(model="text-embedding-3-large")
PERSIST = "C:/Users/SunjaeJeong/Desktop/data/files_data/chroma_recipes_2025_09_16"
COLLECTION = "recipes-v1"

SCORE_THRESHOLD = float(os.environ.get("GROUPA_SCORE_THRESHOLD", "0.0"))
ALLOW_NO_CONTEXT_ANSWER = os.environ.get("ALLOW_NO_CONTEXT_ANSWER", "1") == "1"
ROUTER_MODEL = os.environ.get("GROUPA_ROUTER_MODEL", "gpt-4o-mini")
DEBUG_RAW = os.environ.get("GROUPA_DEBUG_RAW", "0") == "1"

# â”€â”€ Router: ì§ˆì˜ ì˜ë„ íŒë³„ + ì¬ì‘ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROUTER_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ë„ˆëŠ” ìš”ë¦¬ ë„ë©”ì¸ ë¼ìš°í„°ì•¼. ì•„ë˜ ì¤‘ í•˜ë‚˜ì˜ intentë¥¼ ê³ ë¥´ê³  JSONë§Œ ì¶œë ¥í•´.\n"
     "ê°€ëŠ¥í•œ intent: ['recipe','dish_overview','storage','substitution','nutrition','equipment','shopping','unknown','out_of_domain']\n"
     "fields: intent(str), needs_retrieval(bool), rewritten_query(str; ê²€ìƒ‰ ì‹œ ìœ ë¦¬í•˜ê²Œ ì¬ì‘ì„±), notes(str; ì„ íƒ). "
     "ìš”ë¦¬/ë ˆì‹œí”¼/ì¬ë£Œ/ë³´ê´€/ì˜ì–‘/ë„êµ¬/ì¥ë³´ê¸°ë©´ out_of_domainì´ ì•„ë‹˜."),
    ("human", "ì§ˆë¬¸: {q}\n\nJSONìœ¼ë¡œë§Œ ë‹µí•´.")
])

def run_router(query: str) -> Dict[str, Any]:
    llm = ChatOpenAI(model=ROUTER_MODEL, temperature=0)
    try:
        raw = llm.invoke(ROUTER_PROMPT.format_messages(q=query)).content
        start = raw.find("{"); end = raw.rfind("}")
        data = json.loads(raw[start:end+1]) if (start != -1 and end != -1) else {}
    except Exception:
        data = {}
    intent = data.get("intent", "recipe")
    if intent not in ['recipe','dish_overview','storage','substitution','nutrition','equipment','shopping','unknown','out_of_domain']:
        intent = "recipe"
    needs_retrieval = bool(data.get("needs_retrieval", True))
    rewritten_query = data.get("rewritten_query") or query
    notes = data.get("notes", "")
    return {"intent": intent, "needs_retrieval": needs_retrieval, "rewritten_query": rewritten_query, "notes": notes}

# â”€â”€ Intentë³„ í”„ë¡¬í”„íŠ¸ (ì¼ë°˜ ì§€ì‹ í™œìš© í—ˆìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COMMON_RULE = (
    "ì£¼ì˜: ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ë¼. "
    "ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•ŒëŠ” ìµœì†Œ 3ì¤„ ì´ìƒìœ¼ë¡œ, ìš”ë¦¬ëª…ê³¼ ë‹¨ê³„ ìš”ì•½ì„ ë°˜ë“œì‹œ í¬í•¨í•´ ì¶œë ¥í•˜ë¼. "
    "ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë©´ ì¼ë°˜ì ì¸ ìš”ë¦¬ ì§€ì‹ì„ í™œìš©í•´ ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ë¼."
)

RECIPE_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ë ˆì‹œí”¼ ë„ìš°ë¯¸.\n"
     "ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©í•˜ë˜, ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë©´ ì¼ë°˜ ìš”ë¦¬ ì§€ì‹ì„ í™œìš©í•´ ë‹µë³€.\n"
     "ì¶œë ¥ í˜•ì‹: 1) ì¬ë£Œ(ê³„ëŸ‰ í¬í•¨) 2) ë‹¨ê³„(ë²ˆí˜¸ ëª©ë¡) 3) í•µì‹¬ íŒ 4) ë³€í˜•/ëŒ€ì²´ ì˜µì…˜(ìˆìœ¼ë©´).\n"
     "**ì˜ì–‘ ì •ë³´ê°€ ì§ˆë¬¸ì— í¬í•¨ë˜ì—ˆë‹¤ë©´ ì¼ë°˜ì ì¸ ì˜ì–‘ ì •ë³´ë„ ê°„ëµíˆ ì¶”ê°€.**\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

DISH_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ìŒì‹ ì†Œê°œ ë„ìš°ë¯¸. ìš”ë¦¬ì˜ ê°œìš”(íŠ¹ì§•/í’ë¯¸/ë‚œì´ë„/ì†Œìš”ì‹œê°„)ì™€ ê¸°ë³¸ ì¬ë£Œ, ëŒ€í‘œ ë³€í˜•ì„ ì„¤ëª….\n"
     "ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©í•˜ê³ , ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë³´ì™„.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

STORAGE_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ì‹ì¬ë£Œ/ìš”ë¦¬ ë³´ê´€ ë„ìš°ë¯¸. ë³´ê´€ ì˜¨ë„/ìš©ê¸°/ê¸°ê°„/í•´ë™/ì‹í’ˆì•ˆì „ì„ ì„¤ëª….\n"
     "ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©í•˜ê³ , ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ì‹í’ˆ ë³´ê´€ ì§€ì¹¨ ì œê³µ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

SUBSTITUTION_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ëŒ€ì²´ì¬ ë„ìš°ë¯¸. í’ë¯¸/ê¸°ëŠ¥ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì²´ì•ˆê³¼ ë¹„ìœ¨/ì£¼ì˜ì  ì œì‹œ.\n"
     "ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©í•˜ê³ , ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ëŒ€ì²´ì¬ ì§€ì‹ í™œìš©.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

NUTRITION_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ì˜ì–‘ ë„ìš°ë¯¸. ëŒ€ëµì  ì—´ëŸ‰/ì£¼ìš” ì˜ì–‘ì„±ë¶„/ì•Œë ˆë¥´ê²/ì£¼ì˜ì‚¬í•­ ì œê³µ.\n"
     "ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©í•˜ê³ , ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ì˜ì–‘ ì •ë³´ ì œê³µ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

GENERAL_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ìš”ë¦¬ Q&A ë„ìš°ë¯¸. ì§ˆë¬¸ ì·¨ì§€ì— ë§ì¶° ì‹¤ìš©ì ì¸ ë‹µë³€ ì œê³µ.\n"
     "ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©í•˜ê³ , ì—†ìœ¼ë©´ ì¼ë°˜ ìš”ë¦¬ ì§€ì‹ í™œìš©.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

PROMPT_BY_INTENT = {
    "recipe": RECIPE_PROMPT,
    "dish_overview": DISH_PROMPT,
    "storage": STORAGE_PROMPT,
    "substitution": SUBSTITUTION_PROMPT,
    "nutrition": NUTRITION_PROMPT,
    "equipment": GENERAL_PROMPT,
    "shopping": GENERAL_PROMPT,
    "unknown": GENERAL_PROMPT
}

# â”€â”€ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _build_context_new(docs):
    """ë²¡í„° DBì—ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
    contexts = []
    seen = set()
    
    for doc in docs:
        content = getattr(doc, "page_content", "").strip()
        
        if content and len(content) > 100:
            metadata = getattr(doc, "metadata", {})
            url = metadata.get("url", "")
            
            if url and url in seen:
                continue
            if url:
                seen.add(url)
            
            formatted_content = _format_markdown_content(content)
            contexts.append(formatted_content)
    
    return contexts[:5]

def _format_markdown_content(content: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ í•œêµ­ì–´ ì¹œí™”ì ìœ¼ë¡œ ë³€í™˜"""
    content = re.sub(r'^# (.+)$', r'[ì œëª©] \1', content, flags=re.MULTILINE)
    content = re.sub(r'^## Ingredients$', '[ì¬ë£Œ]', content, flags=re.MULTILINE)
    content = re.sub(r'^## Steps$', '[ì¡°ë¦¬ë²•]', content, flags=re.MULTILINE)
    content = re.sub(r'^Source:.*$', '', content, flags=re.MULTILINE)
    content = re.sub(r'^Image:.*$', '', content, flags=re.MULTILINE)
    content = re.sub(r'\n{3,}', '\n\n', content)
    return content.strip()

# â”€â”€ ê²€ìƒ‰ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _search_new(vs, query: str, k: int) -> List[Any]:
    """ë²¡í„° DBì—ì„œ ê²€ìƒ‰"""
    try:
        docs = vs.similarity_search(query, k=k)
        if docs and len(docs) >= 2:
            return docs
        docs = vs.similarity_search(query, k=k*2)
        return docs
    except Exception as e:
        print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

# â”€â”€ API Schemas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AskReq(BaseModel):
    query: str
    k: int = 10
    model: str = "gpt-4o-mini"

@app.get("/health")
def health():
    return {
        "ok": True,
        "persist": PERSIST,
        "collection": COLLECTION,
        "score_threshold": SCORE_THRESHOLD,
        "embed_model": "text-embedding-3-large",
        "total_docs": get_doc_count().get("total_docs", "N/A"),
        "router_model": ROUTER_MODEL,
        "allow_no_context_answer": ALLOW_NO_CONTEXT_ANSWER,
        "status": "ì¼ë°˜ ì§€ì‹ í™œìš© ê°€ëŠ¥ (ì‚¬ìš©ì ê²½í—˜ ìµœì í™”)"
    }

@app.get("/doc_count")
def get_doc_count():
    """ë¬¸ì„œ ê°œìˆ˜ í™•ì¸"""
    try:
        chroma_db = Chroma(collection_name=COLLECTION, embedding_function=EMB, persist_directory=PERSIST)
        count = chroma_db._collection.count()
        return {"total_docs": count}
    except Exception as e:
        return {"error": str(e)}
    
# â”€â”€ ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ (ì¼ë°˜ ì§€ì‹ í™œìš© ë²„ì „) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/ask")
def ask(req: AskReq):
    # 1) Routerë¡œ ì˜ë„ íŒë³„
    route = run_router(req.query)
    intent = route["intent"]
    needs_retrieval = route["needs_retrieval"]
    q_for_search = route["rewritten_query"]

    if intent == "out_of_domain":
        return {
            "answer": "ì£„ì†¡í•´ìš”. ì €ëŠ” ìŒì‹Â·ìš”ë¦¬Â·ë ˆì‹œí”¼Â·ì¬ë£ŒÂ·ë³´ê´€Â·ì˜ì–‘ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µí•©ë‹ˆë‹¤.",
            "retrieved_count": 0, "k": req.k, "sources": [], "router": route
        }

    # 2) ë²¡í„° DB ê²€ìƒ‰
    vs = Chroma(collection_name=COLLECTION, embedding_function=EMB, persist_directory=PERSIST)
    docs, contexts = [], []
    
    if needs_retrieval:
        docs = _search_new(vs, q_for_search, req.k)
        contexts = _build_context_new(docs)

    # 3) ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì—†ì–´ë„ ì§„í–‰ - LLMì´ ì¼ë°˜ ì§€ì‹ í™œìš©)
    context_text = "\n\n---\n\n".join(contexts)[:6000] if contexts else ""
    
    # 4) ì˜ë„ë³„ í”„ë¡¬í”„íŠ¸ë¡œ ë‹µë³€ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ ì—†ì–´ë„ ë‹µë³€ ê°€ëŠ¥)
    llm = ChatOpenAI(model=req.model, temperature=0.3)  # ì•½ê°„ ë†’ì—¬ì„œ ì°½ì˜ì  ë‹µë³€ ê°€ëŠ¥
    prompt = PROMPT_BY_INTENT.get(intent, GENERAL_PROMPT)
    
    try:
        raw_ans = llm.invoke(prompt.format_messages(
            context=context_text or "ì»¨í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ìš”ë¦¬ ì§€ì‹ì„ í™œìš©í•´ ë‹µë³€í•´ì£¼ì„¸ìš”.",
            question=req.query
        )).content
        ans = (raw_ans or "").strip()
    except Exception as e:
        ans = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    # 5) ê°œí–‰ ì •ë¦¬
    ans = re.sub(r"\n{3,}", "\n\n", ans)

    # 6) ì‘ë‹µ (ì»¨í…ìŠ¤íŠ¸ ìœ ë¬´ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ í‘œì‹œ)
    response = {
        "router": route,
        "intent": intent,
        "context_len": len(context_text),
        "used_docs": len(contexts),
        "context_found": bool(contexts),  # ì»¨í…ìŠ¤íŠ¸ ë°œê²¬ ì—¬ë¶€
        "answer": ans,
        "retrieved_count": len(docs),
        "k": req.k,
        "sources": [getattr(d, "metadata", {}) for d in docs][:10],
        "mode": "context_based" if contexts else "general_knowledge"  # ë‹µë³€ ëª¨ë“œ
    }
    
    if DEBUG_RAW:
        response["raw_answer"] = raw_ans
        response["context_preview"] = context_text[:300] if context_text else ""
        
    return response

# â”€â”€ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/test_search/{query}")
def test_search(query: str):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    vs = Chroma(collection_name=COLLECTION, embedding_function=EMB, persist_directory=PERSIST)
    docs = _search_new(vs, query, 5)
    
    results = []
    for doc in docs:
        results.append({
            "title": doc.metadata.get("title", "N/A"),
            "url": doc.metadata.get("url", "N/A"),
            "content_length": len(doc.page_content),
            "content_preview": doc.page_content[:200]
        })
    
    return {
        "query": query,
        "found_docs": len(docs),
        "results": results
    }

# â”€â”€ ì •ì  íŒŒì¼ ì„œë¹™ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/", include_in_schema=False)
async def root():
    return FileResponse(str(STATIC_DIR / "index.html"))

app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")

@app.post("/query")
def query(req: AskReq):
    """í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ìš© ì—”ë“œí¬ì¸íŠ¸"""
    return ask(req)

# â”€â”€ ë¡œì»¬ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("chatbot_rag_oriented_version2:app", host="127.0.0.1", port=8000, reload=True)