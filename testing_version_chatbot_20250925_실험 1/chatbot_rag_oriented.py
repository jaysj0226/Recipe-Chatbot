import os, re, json, unicodedata
from typing import Optional, List, Dict, Any

from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate

# â”€â”€ App / Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
app = FastAPI(title="Group A â€” RAG with LLM Router (Updated)")

# ğŸ”§ ìƒˆë¡œìš´ ë²¡í„° DB ì„¤ì •
EMB = OpenAIEmbeddings(model="text-embedding-3-large")  # ì˜¬ë°”ë¥¸ ëª¨ë¸ ì§€ì •
PERSIST = "C:/Users/SunjaeJeong/Desktop/data/files_data/chroma_recipes_2025_09_16"  # ìƒˆ DB ê²½ë¡œ
COLLECTION = "recipes-v1"  # ìƒˆ ì»¬ë ‰ì…˜ëª…

SCORE_THRESHOLD = float(os.environ.get("GROUPA_SCORE_THRESHOLD", "0.0"))   # 0 = always k
ALLOW_NO_CONTEXT_ANSWER = os.environ.get("ALLOW_NO_CONTEXT_ANSWER", "1") == "1"
ROUTER_MODEL = os.environ.get("GROUPA_ROUTER_MODEL", "gpt-4o-mini")
DEBUG_RAW = os.environ.get("GROUPA_DEBUG_RAW", "0") == "1"  # optional

# â”€â”€ Router: ì§ˆì˜ ì˜ë„ íŒë³„ + ì¬ì‘ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸ few shot ì ìš©!!!
# í…ŒìŠ¤íŠ¸ ë²„ì „
'''
ROUTER_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ë„ˆëŠ” ìš”ë¦¬ ë„ë©”ì¸ ë¼ìš°í„°ì•¼. ì•„ë˜ ì¤‘ í•˜ë‚˜ì˜ intentë¥¼ ê³ ë¥´ê³  JSONë§Œ ì¶œë ¥í•´.\n"
     "ê°€ëŠ¥í•œ intent: ['recipe','dish_overview','storage','substitution','nutrition','equipment','shopping','unknown','out_of_domain']\n"
     "fields: intent(str), needs_retrieval(bool), rewritten_query(str; ê²€ìƒ‰ ì‹œ ìœ ë¦¬í•˜ê²Œ ì¬ì‘ì„±), notes(str; ì„ íƒ). "
     "ìš”ë¦¬/ë ˆì‹œí”¼/ì¬ë£Œ/ë³´ê´€/ì˜ì–‘/ë„êµ¬/ì¥ë³´ê¸°ë©´ out_of_domainì´ ì•„ë‹˜."),
    ("human", "ì§ˆë¬¸: {q}\n\nJSONìœ¼ë¡œë§Œ ë‹µí•´.")
])
'''
ROUTER_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ë„ˆëŠ” ìš”ë¦¬ ë„ë©”ì¸ ë¼ìš°í„°ì•¼. ì•„ë˜ ì¤‘ í•˜ë‚˜ì˜ intentë¥¼ ê³ ë¥´ê³  JSONë§Œ ì¶œë ¥í•´.\n\n"
     "ì¤‘ìš”í•œ êµ¬ë¶„:\n"
     "- out_of_domain: ìš”ë¦¬/ìŒì‹ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ (ë‚ ì”¨, ì½”ë”©, ì£¼ì‹, ì •ì¹˜, ì—°ì• , ê²Œì„ ë“±)\n"
     "- unknown: ìš”ë¦¬ ê´€ë ¨ì´ì§€ë§Œ ì• ë§¤í•œ ì§ˆë¬¸ ('ë­”ê°€ ë§¤ìš´ ê±°', 'ê°„ë‹¨í•œ ìš”ë¦¬ ì¶”ì²œ')\n\n"
     "ê°€ëŠ¥í•œ intent: ['recipe','dish_overview','storage','substitution','nutrition','equipment','shopping','unknown','out_of_domain']\n\n"
     "ì˜ˆì‹œ:\n"
     "- 'ë‚ ì”¨ ì–´ë•Œ?' â†’ out_of_domain\n"
     "- 'íŒŒì´ì¬ ì½”ë”©' â†’ out_of_domain\n" 
     "- 'ì£¼ì‹ íˆ¬ì' â†’ out_of_domain\n"
     "- 'ê¹€ì¹˜ì°Œê°œ ë§Œë“¤ê¸°' â†’ recipe\n"
     "- 'ë­”ê°€ ë§¤ìš´ ê±° ì¶”ì²œ' â†’ unknown\n\n"
     "fields: intent(str), needs_retrieval(bool), rewritten_query(str; ê²€ìƒ‰ ì‹œ ìœ ë¦¬í•˜ê²Œ ì¬ì‘ì„±), notes(str; ì„ íƒ)."),
    ("human", "ì§ˆë¬¸: {q}\n\nJSONìœ¼ë¡œë§Œ ë‹µí•´.")
])
def run_router(query: str) -> Dict[str, Any]:
    llm = ChatOpenAI(model=ROUTER_MODEL, temperature=0)
    try:
        raw = llm.invoke(ROUTER_PROMPT.format_messages(q=query)).content
        start = raw.find("{"); end = raw.rfind("}")
        data = json.loads(raw[start:end+1]) if (start != -1 and end != -1) else {}
    except Exception:
        data = {}
    intent = data.get("intent", "recipe")
    if intent not in ['recipe','dish_overview','storage','substitution','nutrition','equipment','shopping','unknown','out_of_domain']:
        intent = "recipe"
    needs_retrieval = bool(data.get("needs_retrieval", True))
    rewritten_query = data.get("rewritten_query") or query
    notes = data.get("notes", "")

    # ì—…ë°ì´íŠ¸ ë¶€ë¶„: out_of_domainì´ë©´ ë¬´ì¡°ê±´ retrieval ë¶ˆí•„ìš” 
    if intent == "out_of_domain":
        needs_retrieval = False
    return {"intent": intent, "needs_retrieval": needs_retrieval, "rewritten_query": rewritten_query, "notes": notes}

# â”€â”€ Intentë³„ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COMMON_RULE = (
    "ì£¼ì˜: ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì§€ ì•Šìœ¼ë©´ 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ'ì´ë¼ëŠ” ë¬¸êµ¬ë¥¼ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ê³ , "
    "ë°˜ë“œì‹œ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê·¼ê±°ë¥¼ ì°¾ì•„ ë‹µí•˜ë¼. "
    "ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•ŒëŠ” ìµœì†Œ 3ì¤„ ì´ìƒìœ¼ë¡œ, ìš”ë¦¬ëª…(ë˜ëŠ” ë ˆì‹œí”¼ëª…)ê³¼ ë‹¨ê³„ ìš”ì•½ì„ ë°˜ë“œì‹œ í¬í•¨í•´ ì¶œë ¥í•˜ë¼."
)

RECIPE_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ë ˆì‹œí”¼ ë„ìš°ë¯¸.\n"
     "ê°€ëŠ¥í•˜ë©´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì˜ ì‚¬ì‹¤ë§Œ ì‚¬ìš©í•´ ë‹µí•˜ê³ , ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì¹¨ì„ ê°„ê²°íˆ ì œì‹œ.\n"
     "ì¶œë ¥ í˜•ì‹: 1) ì¬ë£Œ(ê³„ëŸ‰ í¬í•¨) 2) ë‹¨ê³„(ë²ˆí˜¸ ëª©ë¡) 3) í•µì‹¬ íŒ 4) ë³€í˜•/ëŒ€ì²´ ì˜µì…˜(ìˆìœ¼ë©´).\n"
     "ì»¨í…ìŠ¤íŠ¸ ì—†ì„ ë•ŒëŠ” 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ'ì´ë¼ê³  í•œ ì¤„ë¡œ ëª…ì‹œ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

DISH_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ìŒì‹ ì†Œê°œ ë„ìš°ë¯¸. ìš”ë¦¬ì˜ ê°œìš”(íŠ¹ì§•/í’ë¯¸/ë‚œì´ë„/ì†Œìš”ì‹œê°„)ì™€ ê¸°ë³¸ ì¬ë£Œ, ëŒ€í‘œ ë³€í˜•ì„ ê°„ê²°íˆ.\n"
     "ì»¨í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì¹¨ + 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ' í‘œì‹œ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

STORAGE_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ì‹ì¬ë£Œ/ìš”ë¦¬ ë³´ê´€ ë„ìš°ë¯¸. ë³´ê´€ ì˜¨ë„/ìš©ê¸°/ê¸°ê°„/í•´ë™/ì‹í’ˆì•ˆì „(ìœ„í—˜ìš”ì†Œ)ì„ ë‹¨ê³„ë³„ë¡œ.\n"
     "ì»¨í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì¹¨ + 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ' í‘œì‹œ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

SUBSTITUTION_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ëŒ€ì²´ì¬ ë„ìš°ë¯¸. í’ë¯¸/ê¸°ëŠ¥(ì ë„, ê²°ì°©, íŒ½ì°½ ë“±) ê¸°ì¤€ìœ¼ë¡œ 1â†’N ëŒ€ì²´ì•ˆì„ í‘œê¸°í•˜ê³ , ë¹„ìœ¨/ì£¼ì˜ì ì„ ëª…ì‹œ.\n"
     "ì»¨í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì¹¨ + 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ' í‘œì‹œ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

NUTRITION_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ì˜ì–‘ ë„ìš°ë¯¸. ëŒ€ëµì  ì—´ëŸ‰/ì£¼ìš” ì˜ì–‘ì„±ë¶„/ì•Œë ˆë¥´ê²/ì£¼ì˜ëŒ€ìƒ(ì €ë‚˜íŠ¸ë¥¨ ë“±)ì„ ê°„ê²°íˆ.\n"
     "ì»¨í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì¹¨ + 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ' í‘œì‹œ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

GENERAL_PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     "ì—­í• : ìš”ë¦¬ Q&A ë„ìš°ë¯¸. ì§ˆë¬¸ ì·¨ì§€ì— ë§ì¶° ê°„ëµí•œ ì²´í¬ë¦¬ìŠ¤íŠ¸/íŒìœ¼ë¡œ ë‹µë³€.\n"
     "ì»¨í…ìŠ¤íŠ¸ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì¹¨ + 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ' í‘œì‹œ.\n" + COMMON_RULE),
    ("human","ì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}")
])

PROMPT_BY_INTENT = {
    "recipe": RECIPE_PROMPT,
    "dish_overview": DISH_PROMPT,
    "storage": STORAGE_PROMPT,
    "substitution": SUBSTITUTION_PROMPT,
    "nutrition": NUTRITION_PROMPT,
    "equipment": GENERAL_PROMPT,
    "shopping": GENERAL_PROMPT,
    "unknown": GENERAL_PROMPT
}

# â”€â”€ ğŸ”§ ìƒˆë¡œìš´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í•¨ìˆ˜ (CSV ì˜ì¡´ì„± ì œê±°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _build_context_new(docs):
    """ìƒˆë¡œìš´ ë²¡í„° DBì—ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (CSV ë¶ˆí•„ìš”)"""
    contexts = []
    seen = set()
    
    for doc in docs:
        # ìƒˆ ë²¡í„° DBëŠ” page_contentê°€ ì™„ì „í•˜ë¯€ë¡œ ì§ì ‘ ì‚¬ìš©
        content = getattr(doc, "page_content", "").strip()
        
        if content and len(content) > 100:  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°
            # ì¤‘ë³µ ì œê±° (URL ê¸°ë°˜)
            metadata = getattr(doc, "metadata", {})
            url = metadata.get("url", "")
            
            if url and url in seen:
                continue
            if url:
                seen.add(url)
            
            # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ë” ì½ê¸° ì‰½ê²Œ ë³€í™˜
            formatted_content = _format_markdown_content(content)
            contexts.append(formatted_content)
    
    return contexts[:5]  # ìƒìœ„ 5ê°œ ë¬¸ì„œë§Œ ì‚¬ìš©

def _format_markdown_content(content: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ í•œêµ­ì–´ ì¹œí™”ì ìœ¼ë¡œ ë³€í™˜"""
    # # ì œëª© â†’ [ì œëª©] í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    content = re.sub(r'^# (.+)$', r'[ì œëª©] \1', content, flags=re.MULTILINE)
    
    # ## Ingredients â†’ [ì¬ë£Œ] í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    content = re.sub(r'^## Ingredients$', '[ì¬ë£Œ]', content, flags=re.MULTILINE)
    
    # ## Steps â†’ [ì¡°ë¦¬ë²•] í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    content = re.sub(r'^## Steps$', '[ì¡°ë¦¬ë²•]', content, flags=re.MULTILINE)
    
    # ë¶ˆí•„ìš”í•œ Source/Image ë¼ì¸ ì œê±°
    content = re.sub(r'^Source:.*$', '', content, flags=re.MULTILINE)
    content = re.sub(r'^Image:.*$', '', content, flags=re.MULTILINE)
    
    # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬
    content = re.sub(r'\n{3,}', '\n\n', content)
    
    return content.strip()

# â”€â”€ ê²€ìƒ‰ í•¨ìˆ˜ (ê°„ì†Œí™”) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _search_new(vs, query: str, k: int) -> List[Any]:
    """ìƒˆë¡œìš´ ë²¡í„° DBì—ì„œ ê²€ìƒ‰ (ê°„ì†Œí™”ëœ ì „ëµ)"""
    try:
        # ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰
        docs = vs.similarity_search(query, k=k)
        if docs and len(docs) >= 2:
            return docs
        
        # ë°±ì—…: ë” ë§ì€ ê²°ê³¼ë¡œ ì¬ì‹œë„
        docs = vs.similarity_search(query, k=k*2)
        return docs
        
    except Exception as e:
        print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

# â”€â”€ API Schemas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AskReq(BaseModel):
    query: str
    k: int = 10
    model: str = "gpt-4o-mini"
'''
@app.get("/health")
def health():
    return {
        "ok": True,
        "persist": PERSIST,
        "collection": COLLECTION,
        "score_threshold": SCORE_THRESHOLD,
        "embed_model": "text-embedding-3-large",
        "router_model": ROUTER_MODEL,
        "allow_no_context_answer": ALLOW_NO_CONTEXT_ANSWER,
        "total_docs": Chroma(collection_name=COLLECTION, embedding_function=EMB, persist_directory=PERSIST).count(),
        "status": "ìƒˆ ë²¡í„° DB ì ìš©ë¨"
    }
'''
# ë°©ë²• 3: ë³„ë„ì˜ ì¹´ìš´íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ë§Œë“¤ê¸°
@app.get("/health")
def health():
    return {
        "ok": True,
        "persist": PERSIST,
        "collection": COLLECTION,
        "score_threshold": SCORE_THRESHOLD,
        "embed_model": "text-embedding-3-large",
        "total_docs": get_doc_count().get("total_docs", "N/A"),
        "router_model": ROUTER_MODEL,
        "allow_no_context_answer": ALLOW_NO_CONTEXT_ANSWER,
        "status": "ìƒˆ ë²¡í„° DB ì ìš©ë¨"
    }

@app.get("/doc_count")
def get_doc_count():
    """ë³„ë„ë¡œ ë¬¸ì„œ ê°œìˆ˜ë¥¼ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©"""
    try:
        chroma_db = Chroma(collection_name=COLLECTION, embedding_function=EMB, persist_directory=PERSIST)
        count = chroma_db._collection.count()
        return {"total_docs": count}
    except Exception as e:
        return {"error": str(e)}
    
# â”€â”€ ğŸ”§ ì—…ë°ì´íŠ¸ëœ ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/ask")
def ask(req: AskReq):
    # 1) LLM Routerë¡œ ì˜ë„/ì „ëµ ê²°ì •
    route = run_router(req.query)
    intent = route["intent"]
    needs_retrieval = route["needs_retrieval"]
    q_for_search = route["rewritten_query"]

    if intent == "out_of_domain":
        return {
            "answer": "ì£„ì†¡í•´ìš”. ì €ëŠ” ìŒì‹Â·ìš”ë¦¬Â·ë ˆì‹œí”¼Â·ì¬ë£ŒÂ·ë³´ê´€Â·ì˜ì–‘ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µí•©ë‹ˆë‹¤.",
            "retrieved_count": 0, "k": req.k, "sources": [], "router": route
        }

    # 2) ìƒˆë¡œìš´ ë²¡í„° DBì—ì„œ ê²€ìƒ‰
    vs = Chroma(collection_name=COLLECTION, embedding_function=EMB, persist_directory=PERSIST)
    docs, contexts = [], []
    
    if needs_retrieval:
        docs = _search_new(vs, q_for_search, req.k)
        contexts = _build_context_new(docs)

    # 3) ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ëŠ”ë° ë¬´ê·¼ê±° í—ˆìš© X â†’ ê±°ì ˆ
    if not contexts and not ALLOW_NO_CONTEXT_ANSWER:
        return {
            "answer": "ê´€ë ¨ëœ ë ˆì‹œí”¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ìš”ë¦¬ëª…ì´ë‚˜ ì¬ë£Œë¥¼ í¬í•¨í•´ì„œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.",
            "retrieved_count": 0, "k": req.k, "sources": [], "router": route
        }

    # 4) ì˜ë„ë³„ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±
    context_text = "\n\n---\n\n".join(contexts)[:6000]
    llm = ChatOpenAI(model=req.model, temperature=0.2)
    prompt = PROMPT_BY_INTENT.get(intent, GENERAL_PROMPT)
    
    try:
        raw_ans = llm.invoke(prompt.format_messages(context=context_text, question=req.query)).content
        ans = (raw_ans or "").strip()
    except Exception as e:
        ans = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    # 5) ë‹µë³€ í›„ì²˜ë¦¬
    if context_text.strip() and ans:
        # 'ê·¼ê±° ë¬¸ì„œ ì—†ìŒ' ì œê±° (ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œ)
        cleaned = re.sub(r"ê·¼ê±°\s*ë¬¸ì„œ\s*ì—†ìŒ", "", ans).strip()
        if cleaned:
            ans = cleaned

    # 6) ë°±ì—… ë‹µë³€ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ëŠ” ìˆì§€ë§Œ ë‹µë³€ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°)
    if context_text.strip() and (not ans or len(ans.strip()) < 50):
        ans = _generate_fallback_answer(context_text, req.query)

    # 7) ê°œí–‰ ì •ë¦¬
    ans = re.sub(r"\n{3,}", "\n\n", ans)

    # 8) ì‘ë‹µ
    response = {
        "router": route,
        "intent": intent,
        "context_len": len(context_text),
        "used_docs": len(contexts),
        "context_preview": context_text[:300] if context_text else "",
        "answer": ans,
        "retrieved_count": len(docs),
        "k": req.k,
        "sources": [getattr(d, "metadata", {}) for d in docs][:10],
        "persist": PERSIST,
        "collection": COLLECTION,
        "db_version": "new_vectordb_2025_09_16"
    }
    
    if DEBUG_RAW:
        response["raw_answer"] = raw_ans
        
    return response

def _generate_fallback_answer(context_text: str, query: str) -> str:
    """ì»¨í…ìŠ¤íŠ¸ëŠ” ìˆì§€ë§Œ ë‹µë³€ì´ ë¶€ì¡±í•œ ê²½ìš° ë°±ì—… ë‹µë³€ ìƒì„±"""
    # ì œëª© ì¶”ì¶œ
    title_match = re.search(r'\[ì œëª©\]\s*(.+)', context_text)
    title = title_match.group(1).strip() if title_match else "ë ˆì‹œí”¼"
    
    # ì¬ë£Œ ì¶”ì¶œ
    ingredients_match = re.search(r'\[ì¬ë£Œ\]\s*(.*?)(?:\[|$)', context_text, re.DOTALL)
    ingredients = ingredients_match.group(1).strip()[:200] if ingredients_match else ""
    
    # ì¡°ë¦¬ë²• ì¶”ì¶œ  
    steps_match = re.search(r'\[ì¡°ë¦¬ë²•\]\s*(.*?)(?:\[|$)', context_text, re.DOTALL)
    steps = steps_match.group(1).strip()[:300] if steps_match else ""
    
    parts = [f"**{title}**"]
    
    if ingredients:
        parts.append(f"\n**ì¬ë£Œ:**\n{ingredients}")
    
    if steps:
        parts.append(f"\n**ì¡°ë¦¬ë²•:**\n{steps}")
    
    if not ingredients and not steps:
        parts.append("\nì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë ˆì‹œí”¼ ì •ë³´ë¥¼ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.")
    
    return "\n".join(parts)

# â”€â”€ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/test_search/{query}")
def test_search(query: str):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸"""
    vs = Chroma(collection_name=COLLECTION, embedding_function=EMB, persist_directory=PERSIST)
    docs = _search_new(vs, query, 5)
    
    results = []
    for doc in docs:
        results.append({
            "title": doc.metadata.get("title", "N/A"),
            "url": doc.metadata.get("url", "N/A"),
            "content_length": len(doc.page_content),
            "content_preview": doc.page_content[:200]
        })
    
    return {
        "query": query,
        "found_docs": len(docs),
        "results": results
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)